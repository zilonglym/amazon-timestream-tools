{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Ingestor Tool - Test Runbook\n",
    "\n",
    "## Contents\n",
    "- [Prerequesites](#Prerequesites)\n",
    "- [Ensure database](#Ensure-database)\n",
    "- [Basic Testing](#Basic-Testing)\n",
    "  - [TEST 0: Regression Parameter](#TEST-0:-Regression-Parameter)\n",
    "  - [TEST 1: Default Parameter](#TEST-1:-Default-Parameter)\n",
    "  - [TEST 2: Single Threaded Ingestion](#TEST-2:-Single-Threaded-Ingestion)\n",
    "  - [TEST 3: Records with High Concurrency](#TEST-3:-Records-with-High-Concurrency)\n",
    "  - [TEST 4: High Concurrency and Scale Factor](#TEST-4:-High-Concurrency-and-Scale-Factor)\n",
    "- [DryRun and Include Parameter Testing](#DryRun-and-Include-Parameter-Testing)\n",
    "  - [TEST 5: DryRun](#TEST-5:-DryRun)\n",
    "  - [TEST 6: Include Only EU Central](#TEST-6:-Include-Only-EU-Central)\n",
    "  - [TEST 7: Include Only Athena Microservice](#TEST-7:-Include-Only-Athena-Microservice)\n",
    "- [Missing Values Testing](#Missing-Values-Testing)\n",
    "  - [TEST 8: Missing Values](#TEST-8:-Missing-Values)\n",
    "- [Signal Values Testing](#Signal-Values-Testing)\n",
    "  - [TEST 9: Sinus Signal Values SNR100](#TEST-9:-Sinus-Signal-Values-SNR100)\n",
    "  - [TEST 10: Sinus Signal Values SNR20](#TEST-10:-Sinus-Signal-Values-SNR20)\n",
    "  - [TEST 11: Sinus Signal Values SNR1](#TEST-11:-Sinus-Signal-Values-SNR1)\n",
    "  - [TEST 12: Saw Signal Values SNR100](#TEST-12:-Saw-Signal-Values-SNR100)\n",
    "  - [TEST 13: Saw Signal Values SNR10](#TEST-13:-Saw-Signal-Values-SNR10)\n",
    "- [Visualization of Signals](#Visualization-of-Signals)\n",
    "- [Cleanup: Drop Tables and Database](#Cleanup:-Drop-Tables-and-Database)\n",
    "\n",
    "## Prerequesites:\n",
    "1. Start a Sagemaker Studio / Sagemaker Notebook as outlined:  [Amazon Timestream - Amazon SageMaker](https://docs.aws.amazon.com/timestream/latest/developerguide/Sagemaker.html)\n",
    "\n",
    "2. Clone the Github Repository: [Amazon Timestream Tools and Samples](https://github.com/awslabs/amazon-timestream-tools.git)\n",
    "\n",
    "3. Change to the folder ```./tools/continuous-ingestor/```\n",
    "\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore\n",
    "from botocore.config import Config\n",
    "\n",
    "sys.path.insert(0, '../../') # add project base folder to path\n",
    "import integrations.sagemaker.timestreamquery as timestream\n",
    "\n",
    "#################################################\n",
    "##### Timestream Configurations.  ###############\n",
    "#################################################\n",
    "\n",
    "REGION = \"eu-west-1\" # <--- specify the region service endpoint\n",
    "PROFILE = \"default\" # <--- specify the AWS credentials profile\n",
    "DB_NAME = \"DemoAndTest01\" # <--- specify the database created in Amazon Timestream\n",
    "\n",
    "session = boto3.Session()\n",
    "read_client = session.client('timestream-query' , region_name = REGION, config = Config())\n",
    "write_client = session.client('timestream-write', region_name = REGION, config = Config())\n",
    "\n",
    "print(\"Read and Write Clients for Amazon Timestream created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure database\n",
    "The following cell will create a new database with the previously defined database name and table name.\n",
    "The new table has a 24h retention period for memory and a 5 years retention on magnetic. (Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreateTable(tableName, databaseName):\n",
    "    try:\n",
    "        write_client.delete_table(DatabaseName=databaseName, TableName=tableName)\n",
    "        print(\"Table <{}> in database <{}> deleted.\".format(tableName, databaseName))\n",
    "    except:\n",
    "        pass\n",
    "    write_client.create_table(DatabaseName=databaseName, TableName=tableName,\\\n",
    "                                 RetentionProperties={'MemoryStoreRetentionPeriodInHours': 24,\\\n",
    "                                                      'MagneticStoreRetentionPeriodInDays': 5 * 365})\n",
    "    print(\"Table's <{}> in database <{}> (re)created.\".format(tableName,databaseName))\n",
    "\n",
    "# CREATE Database if not exists.\n",
    "try:\n",
    "    write_client.create_database(DatabaseName=DB_NAME)\n",
    "    print(\"Database <{}> created.\".format(DB_NAME))\n",
    "except:\n",
    "    print(\"Database <{}> exists already.\".format(DB_NAME))\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Testing\n",
    "In this section we run the standard parametrized ingestions as described in the README.md (Back to [top](#Contents))\n",
    "\n",
    "### TEST 0: Regression Parameter\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 0: Start continuous ingestor and generate exactly 1 record per time series with legacy endpoint parameter \n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME0 = \"DevOpsTest00\"\n",
    "recreateTable(TABLE_NAME0, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME0\" --endpoint \"$REGION\" --autostop 1\n",
    "\n",
    "ENDPOINT_URL='https://ingest-cell1.timestream.' + REGION + '.amazonaws.com'\n",
    "%run timestream_sample_continuous_data_ingestor_application.py \\\n",
    "  -d \"$DB_NAME\" -t \"$TABLE_NAME0\" -e \"$REGION\" -url \"$ENDPOINT_URL\" --autostop 1\n",
    "\n",
    "query = \"\"\"DESCRIBE {}.{}\"\"\".format(DB_NAME, TABLE_NAME0)\n",
    "result = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 1: Default Parameter\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 1: Start continuous ingestor and generate exactly 5 records per time series with default parameter \n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME1 = \"DevOpsTest01\"\n",
    "recreateTable(TABLE_NAME1, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME1\" --region \"$REGION\" --autostop 5\n",
    "\n",
    "query = \"\"\"DESCRIBE {}.{}\"\"\".format(DB_NAME, TABLE_NAME1)\n",
    "result = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 server metric values for 1010 different machines/dimension sets   =>  20,200 unique metric time series\n",
    "#  5 process event values from 1212 different processes/dimension sets =>   6,060 unique event time series\n",
    "\n",
    "# AUTOSTOP after 5 values per time series => (20,200 + 6,060) * 5 = 131,300 values\n",
    "query = \"\"\"SELECT count(1) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME1)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1)\n",
    "query = \"\"\"SELECT measure_name, count(1) as cnt,  process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "             FROM {}.{} \n",
    "            WHERE 1=1 \n",
    "              AND process_name is null\n",
    "            GROUP BY measure_name, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "            ORDER BY cnt, region, availability_zone\"\"\".format(DB_NAME, TABLE_NAME1)\n",
    "result2 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result2)\n",
    "query = \"\"\"SELECT measure_name, count(1) as cnt, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "             FROM {}.{} \n",
    "            WHERE 1=1  \n",
    "              AND process_name is not null\n",
    "            GROUP BY measure_name, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "            ORDER BY cnt, region, availability_zone\"\"\".format(DB_NAME, TABLE_NAME1)\n",
    "result3 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result3)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 131300:\n",
    "    print('\\x1B[91m' + 'TEST 1-1: FAILED: We expect exactly 131300 total values. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 1-1: SUCCESS: We expect exactly 131300 total values.')\n",
    "\n",
    "\n",
    "if len(result2['cnt']) != 20200:\n",
    "    print('\\x1B[91m' + 'TEST 1-2: FAILED: We expect 20200 metric time series. Actual {}'.format(result2['cnt']))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 1-2: SUCCESS: We expect 20200 metric time series.')\n",
    "    \n",
    "\n",
    "if len(result3['cnt']) != 6060:\n",
    "    print('\\x1B[91m' + 'TEST 1-3: FAILED: We expect 6060 event time series. Actual {}'.format(result3['cnt']))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 1-3: SUCCESS: We expect 6060 event time series.')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 1: DONE') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 2: Single Threaded Ingestion\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 2: Start continuous ingestor and generate exactly 1 record with single threaded parametrization\n",
    "###################################################################################################\n",
    "TABLE_NAME2 = \"DevOpsTest02\"\n",
    "recreateTable(TABLE_NAME2, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py \\\n",
    "  -c 1 -s 1 -d \"$DB_NAME\" -t \"$TABLE_NAME2\" -r \"$REGION\" --autostop 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 server metric values for 1010 different machines/dimension sets   =>  20,200 unique metric time series\n",
    "#  5 process event values from 1212 different processes/dimension sets =>   6,060 unique event time series\n",
    "\n",
    "# AUTOSTOP after 1 value per time series => (20,200 + 6,060) * 1 = 26,260 values\n",
    "query = \"\"\"SELECT count(1) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME2)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1)\n",
    "query = \"\"\"SELECT measure_name, count(1) as cnt,  process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "             FROM {}.{} \n",
    "            WHERE 1=1 \n",
    "              AND process_name is null\n",
    "            GROUP BY measure_name, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "            ORDER BY cnt, region, availability_zone\"\"\".format(DB_NAME, TABLE_NAME2)\n",
    "result2 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result2)\n",
    "query = \"\"\"SELECT measure_name, count(1) as cnt, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "             FROM {}.{} \n",
    "            WHERE 1=1  \n",
    "              AND process_name is not null\n",
    "            GROUP BY measure_name, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "            ORDER BY cnt, region, availability_zone\"\"\".format(DB_NAME, TABLE_NAME2)\n",
    "result3 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result3)\n",
    "\n",
    "if result1['cnt'][0] != 26260:\n",
    "    print('\\x1B[91m' + 'TEST 2-1: FAILED: We expect exactly 26260 total values. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 2-1: SUCCESS: We expect exactly 26260 total values.')\n",
    "\n",
    "\n",
    "if len(result2['cnt']) != 20200:\n",
    "    print('\\x1B[91m' + 'TEST 2-2: FAILED: We expect 20200 metric time series. Actual {}'.format(result2['cnt']))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 2-2: SUCCESS: We expect 20200 metric time series.')\n",
    "    \n",
    "\n",
    "if len(result3['cnt']) != 6060:\n",
    "    print('\\x1B[91m' + 'TEST 2-3: FAILED: We expect 6060 event time series. Actual {}'.format(result3['cnt']))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 2-3: SUCCESS: We expect 6060 event time series.')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 2: DONE') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 3: Records with High Concurrency\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 3: Start continuous ingestor and generate exactly 5 records per time series with high concurrency parameter \n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME3 = \"DevOpsTest03\"\n",
    "recreateTable(TABLE_NAME3, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME3\" --region \"$REGION\" --concurrency 30 --autostop 5\n",
    "\n",
    "query = \"\"\"DESCRIBE {}.{}\"\"\".format(DB_NAME, TABLE_NAME3)\n",
    "result = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 server metric values for 1010 different machines/dimension sets   =>  20,200 unique metric time series\n",
    "#  5 process event values from 1212 different processes/dimension sets =>   6,060 unique event time series\n",
    "\n",
    "# AUTOSTOP after 5 values per time series => (20,200 + 6,060) * 5 = 131,300 values\n",
    "query = \"\"\"SELECT count(1) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME3)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1)\n",
    "query = \"\"\"SELECT measure_name, count(1) as cnt,  process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "             FROM {}.{} \n",
    "            WHERE 1=1 \n",
    "              AND process_name is null\n",
    "            GROUP BY measure_name, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "            ORDER BY cnt, region, availability_zone\"\"\".format(DB_NAME, TABLE_NAME3)\n",
    "result2 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result2)\n",
    "query = \"\"\"SELECT measure_name, count(1) as cnt, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "             FROM {}.{} \n",
    "            WHERE 1=1  \n",
    "              AND process_name is not null\n",
    "            GROUP BY measure_name, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "            ORDER BY cnt, region, availability_zone\"\"\".format(DB_NAME, TABLE_NAME3)\n",
    "result3 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result3)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 131300:\n",
    "    print('\\x1B[91m' + 'TEST 3-1: FAILED: We expect exactly 131300 total values. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 3-1: SUCCESS: We expect exactly 131300 total values.')\n",
    "\n",
    "\n",
    "if len(result2['cnt']) != 20200:\n",
    "    print('\\x1B[91m' + 'TEST 3-2: FAILED: We expect 20200 metric time series. Actual {}'.format(result2['cnt']))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 3-2: SUCCESS: We expect 20200 metric time series.')\n",
    "    \n",
    "\n",
    "if len(result3['cnt']) != 6060:\n",
    "    print('\\x1B[91m' + 'TEST 3-3: FAILED: We expect 6060 event time series. Actual {}'.format(result3['cnt']))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 3-3: SUCCESS: We expect 6060 event time series.')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 3: DONE') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 4: High Concurrency and Scale Factor\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 4: Start continuous ingestor and generate exactly 5 records per time series with scale factor and high concurrency parameter \n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME4 = \"DevOpsTest04\"\n",
    "recreateTable(TABLE_NAME4, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME4\" --region \"$REGION\" --concurrency 30 --host-scale 5 --autostop 3\n",
    "\n",
    "query = \"\"\"DESCRIBE {}.{}\"\"\".format(DB_NAME, TABLE_NAME4)\n",
    "result = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 server metric values for 1010 * 5 scale factor different machines/dimension sets   =>  101,000 unique metric time series\n",
    "#  5 process event values from 1212 * 5 scale factor different processes/dimension sets =>   30,300 unique event time series\n",
    "\n",
    "# AUTOSTOP after 3 values per time series => (101,000 + 30,300) * 3 = 393,900 values\n",
    "query = \"\"\"SELECT count(1) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME4)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1)\n",
    "query = \"\"\"SELECT measure_name, count(1) as cnt,  process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "             FROM {}.{} \n",
    "            WHERE 1=1 \n",
    "              AND process_name is null\n",
    "            GROUP BY measure_name, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "            ORDER BY cnt, region, availability_zone\"\"\".format(DB_NAME, TABLE_NAME4)\n",
    "result2 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result2)\n",
    "query = \"\"\"SELECT measure_name, count(1) as cnt, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "             FROM {}.{} \n",
    "            WHERE 1=1  \n",
    "              AND process_name is not null\n",
    "            GROUP BY measure_name, process_name, microservice_name, instance_name, silo, region, availability_zone\n",
    "            ORDER BY cnt, region, availability_zone\"\"\".format(DB_NAME, TABLE_NAME4)\n",
    "result3 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result3)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 393900:\n",
    "    print('\\x1B[91m' + 'TEST 4-1: FAILED: We expect exactly 393900 total values. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 4-1: SUCCESS: We expect exactly 393900 total values.')\n",
    "\n",
    "\n",
    "if len(result2['cnt']) != 101000:\n",
    "    print('\\x1B[91m' + 'TEST 4-2: FAILED: We expect 101000 metric time series. Actual {}'.format(result2['cnt']))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 4-2: SUCCESS: We expect 101000 metric time series.')\n",
    "    \n",
    "\n",
    "if len(result3['cnt']) != 30300:\n",
    "    print('\\x1B[91m' + 'TEST 4-3: FAILED: We expect 30300 event time series. Actual {}'.format(result3['cnt']))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 4-3: SUCCESS: We expect 30300 event time series.')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 4: DONE') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DryRun and Include Parameter Testing\n",
    "(Back to [top](#Contents))\n",
    "\n",
    "### TEST 5: DryRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 5: Run ingestor in dry run to skip writing records actually\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME5 = \"DevOpsTest05\"\n",
    "recreateTable(TABLE_NAME5, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME5\" --region \"$REGION\" --autostop 5 --dry-run\n",
    "\n",
    "query = \"\"\"DESCRIBE {}.{}\"\"\".format(DB_NAME, TABLE_NAME5)\n",
    "result = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOSTOP after 5 iterations, --dry-run is quicker, but no records stored.\n",
    "query = \"\"\"SELECT count(1) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME5)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1)\n",
    "\n",
    "if result1['cnt'][0] != 0:\n",
    "    print('\\x1B[91m' + 'TEST 5-1: FAILED: We expect no records.')\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 5-1: SUCCESS: We expect no records.')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 5: DONE') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 6: Include Only EU Central\n",
    "(Back to [top](#Contents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 6: Run ingestor for data in 'eu-central-1' only (1 cell, 1 silo)\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME6 = \"DevOpsTest06\"\n",
    "recreateTable(TABLE_NAME6, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 5\\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME6\" --region \"$REGION\" --include-region \"eu-central-1\"\n",
    "\n",
    "query = \"\"\"DESCRIBE {}.{}\"\"\".format(DB_NAME, TABLE_NAME6)\n",
    "result = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 server metric values for 10 different machines/dimension sets   =>  200 unique metric time series\n",
    "#  5 process event values from 12 different processes/dimension sets =>   60 unique event time series\n",
    "\n",
    "# AUTOSTOP after 5 iterations, 260 * 5 = 1300\n",
    "query = \"\"\"SELECT count(1) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME6)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1)\n",
    "\n",
    "query = \"\"\"SELECT count(distinct region) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME6)\n",
    "result2 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result2)\n",
    "\n",
    "query = \"\"\"SELECT count(1) as cnt, region\n",
    "             FROM {}.{}\n",
    "            GROUP BY region\"\"\".format(DB_NAME, TABLE_NAME6)\n",
    "result3 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result3)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 1300:\n",
    "    print('\\x1B[91m' + 'TEST 6-1: FAILED: We expect 1300 records. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 6-1: SUCCESS: We expect 1300 records.')\n",
    "\n",
    "    \n",
    "if result2['cnt'][0] != 1:\n",
    "    print('\\x1B[91m' + 'TEST 6-2: FAILED: We expect exactly one region. Actual {}'.format(result2['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 6-2: SUCCESS: We expect exactly one region.')\n",
    "\n",
    "if result3['region'][0] != 'eu-central-1':\n",
    "    print('\\x1B[91m' + 'TEST 6-3: FAILED: We expect <eu-central-1> as region. Actual {}'.format(result3['region'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 6-3: SUCCESS: We expect <eu-central-1> as region.')\n",
    "\n",
    "if result3['cnt'][0] != 1300:\n",
    "    print('\\x1B[91m' + 'TEST 6-4: FAILED: We expect 1300 records in <eu-central-1> region. Actual {}'.format(result3['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 6-4: SUCCESS: We expect 1300 records in <eu-central-1> region.')\n",
    "    \n",
    "print('\\x1b[0m' + 'TEST 6: DONE') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 7: Include Only Athena Microservice\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 7: Run ingestor for data in 'eu-central-1' only (1 cell, 1 silo) and a limit on microservice 'athena'\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME7 = \"DevOpsTest07\"\n",
    "recreateTable(TABLE_NAME7, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 5\\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME7\" --region \"$REGION\" --include-ms \"athena\"\n",
    "\n",
    "query = \"\"\"DESCRIBE {}.{}\"\"\".format(DB_NAME, TABLE_NAME7)\n",
    "result = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 server metric values for 101 different machines/dimension sets and 1 service   =>  2020 unique metric time series\n",
    "#  5 process event values from 202 different processes/dimension sets and 1 service with 2 processes =>   1010 unique event time series\n",
    "\n",
    "# AUTOSTOP after 5 iterations, 3030 * 5 = 15150\n",
    "query = \"\"\"SELECT count(1) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME7)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1)\n",
    "\n",
    "query = \"\"\"SELECT count(distinct microservice_name) as cnt\n",
    "             FROM {}.{}\"\"\".format(DB_NAME, TABLE_NAME7)\n",
    "result2 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result2)\n",
    "\n",
    "query = \"\"\"SELECT count(1) as cnt, microservice_name\n",
    "             FROM {}.{}\n",
    "            GROUP BY microservice_name\"\"\".format(DB_NAME, TABLE_NAME7)\n",
    "result3 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "display.display(result3)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 15150:\n",
    "    print('\\x1B[91m' + 'TEST 7-1: FAILED: We expect 1300 records. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 7-1: SUCCESS: We expect 1300 records.')\n",
    "\n",
    "    \n",
    "if result2['cnt'][0] != 1:\n",
    "    print('\\x1B[91m' + 'TEST 7-2: FAILED: We expect exactly one microservice. Actual {}'.format(result2['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 7-2: SUCCESS: We expect exactly one microservice.')\n",
    "\n",
    "if result3['microservice_name'][0] != 'athena':\n",
    "    print('\\x1B[91m' + 'TEST 7-3: FAILED: We expect <athena> as microservice. Actual {}'.format(result3['microservice_name'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 7-3: SUCCESS: We expect <athena> as microservice.')\n",
    "\n",
    "if result3['cnt'][0] != 15150:\n",
    "    print('\\x1B[91m' + 'TEST 7-4: FAILED: We expect 15150 records for <athena> microservice. Actual {}'.format(result3['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 7-4: SUCCESS: We expect 15150 records for <athena> microservice.')\n",
    "    \n",
    "print('\\x1b[0m' + 'TEST 7: DONE') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values Testing\n",
    "### TEST 8: Missing Values\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 8: Run ingestor simulating 'eu-central-1' and 'athena' service with missing values.\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME825 = \"DevOpsTest0825\"\n",
    "recreateTable(TABLE_NAME825, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 25\\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME825\" --region \"$REGION\" --include-region \"eu-central-1\" --include-ms \"athena\" --missing-cpu 25 --seed 1234\n",
    "\n",
    "TABLE_NAME875 = \"DevOpsTest0875\"\n",
    "recreateTable(TABLE_NAME875, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 25\\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME875\" --region \"$REGION\" --include-region \"eu-central-1\" --include-ms \"athena\" --missing-cpu 75 --seed 1234\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT count(1), measure_name\n",
    "             FROM {}.{}\n",
    "            WHERE 1=1\n",
    "              AND microservice_name = 'athena'\n",
    "              AND measure_name IN ('cpu_user', 'cpu_idle', 'network_bytes_in', 'memory_used')\n",
    "            GROUP BY measure_name\"\"\".format(DB_NAME, TABLE_NAME825)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1.head(20))\n",
    "\n",
    "\n",
    "query = \"\"\"SELECT count(1) as cnt, measure_name\n",
    "             FROM {0}.{1}\n",
    "            WHERE 1=1\n",
    "              AND microservice_name = 'athena'\n",
    "              AND measure_name IN ('{2}')\n",
    "            GROUP BY measure_name\"\"\"\n",
    "\n",
    "result2 = timestream.executeQueryAndReturnAsDataframe(read_client, query.format(DB_NAME, TABLE_NAME825, 'memory_used'), True)\n",
    "#display.display(result2.head(20))\n",
    "\n",
    "result3 = timestream.executeQueryAndReturnAsDataframe(read_client, query.format(DB_NAME, TABLE_NAME825, 'cpu_user'), True)\n",
    "#display.display(result3.head(20))\n",
    "\n",
    "if result2['cnt'][0] != 25:\n",
    "    print('\\x1B[91m' + 'TEST 8-1: FAILED: We expect 25 memory records. Actual {}'.format(result2['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 8-1: SUCCESS: We expect 25 memory records.')\n",
    "\n",
    "# we can expect the same number of missing cpu signals due to fixed seed.\n",
    "# 25% missing values of 25 = 18 to 20\n",
    "if result3['cnt'][0] != 19:\n",
    "    print('\\x1B[91m' + 'TEST 8-2: FAILED: We expect 19 cpu records. Actual {}'.format(result3['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 8-2: SUCCESS: We expect 19 cpu records.')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 8 (25%): DONE') \n",
    "\n",
    "\n",
    "query = \"\"\"SELECT count(1), measure_name\n",
    "             FROM {}.{}\n",
    "            WHERE 1=1\n",
    "              AND microservice_name = 'athena'\n",
    "              AND measure_name IN ('cpu_user', 'cpu_idle', 'network_bytes_in', 'memory_used')\n",
    "            GROUP BY measure_name\"\"\".format(DB_NAME, TABLE_NAME875)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "#display.display(result1.head(20))\n",
    "\n",
    "\n",
    "query = \"\"\"SELECT count(1) as cnt, measure_name\n",
    "             FROM {0}.{1}\n",
    "            WHERE 1=1\n",
    "              AND microservice_name = 'athena'\n",
    "              AND measure_name IN ('{2}')\n",
    "            GROUP BY measure_name\"\"\"\n",
    "\n",
    "result2 = timestream.executeQueryAndReturnAsDataframe(read_client, query.format(DB_NAME, TABLE_NAME875, 'memory_used'), True)\n",
    "#display.display(result2.head(20))\n",
    "\n",
    "result3 = timestream.executeQueryAndReturnAsDataframe(read_client, query.format(DB_NAME, TABLE_NAME875, 'cpu_user'), True)\n",
    "#display.display(result3.head(20))\n",
    "\n",
    "if result2['cnt'][0] != 25:\n",
    "    print('\\x1B[91m' + 'TEST 8-3: FAILED: We expect 25 memory records. Actual {}'.format(result2['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 8-3: SUCCESS: We expect 25 memory records.')\n",
    "\n",
    "# we can expect the same number of missing cpu signals due to fixed seed.\n",
    "# 75% missing values of 25 = 5 to 7\n",
    "if result3['cnt'][0] != 7:\n",
    "    print('\\x1B[91m' + 'TEST 8-4: FAILED: We expect 7 cpu records. Actual {}'.format(result3['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 8-4: SUCCESS: We expect 7 cpu records.')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 8 (75%): DONE') \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Values Testing\n",
    "### TEST 9: Sinus Signal Values SNR100\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 9: Run ingestor simulating 'eu-central-1' and 'athena' service with sinus signal on CPU (no noise)\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME9SNR100 = \"DevOpsTest09SNR100\"\n",
    "recreateTable(TABLE_NAME9SNR100, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 120  --seed 1234 \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME9SNR100\" --region \"$REGION\" \\\n",
    "  --include-region \"eu-central-1\" --include-ms \"athena\" \\\n",
    "  --sin-signal-cpu 100 --sin-frq-cpu m \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"WITH offsetted AS (\n",
    "         SELECT time, \n",
    "                measure_value::double value,\n",
    "                lag(time, 60) OVER (order by time rows 60 preceding) as lagtime,\n",
    "                lag(measure_value::double, 60) OVER (order by time rows 60 preceding) as lagvalue\n",
    "           FROM {}.{}\n",
    "          WHERE 1=1\n",
    "            AND measure_name = 'cpu_user')\n",
    "         SELECT count(1) as cnt, round(sum(value), 2) as sum, round(sum(value - lagvalue),2) as dif\n",
    "           FROM offsetted\n",
    "          WHERE lagtime is not null\"\"\".format(DB_NAME, TABLE_NAME9SNR100)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 60:\n",
    "    print('\\x1B[91m' + 'TEST 9-1: FAILED: We expect 60 records with value and lagvalue. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 9-1: SUCCESS: We expect 60 records with value and lagvalue.')\n",
    "\n",
    "if result1['sum'][0] != 3000:\n",
    "    print('\\x1B[91m' + 'TEST 9-2: FAILED: We expect a sum of 3000. Actual {}'.format(result1['sum'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 9-2: SUCCESS: We expect a sum of 3000')\n",
    "\n",
    "if result1['dif'][0] != 0:\n",
    "    print('\\x1B[91m' + 'TEST 9-3: FAILED: We expect a difference of 0. Actual {}'.format(result1['dif'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 9-3: SUCCESS: We expect a difference of 0')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 9: DONE') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 10: Sinus Signal Values SNR20\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 10 SNR: Run ingestor simulating 'eu-central-1' and 'athena' service with sinus signal on CPU with SNR=20\n",
    "## Signal 20x stronger than noise => noise = [-2.5 ... 2.5] for signal = [0 ... 100]\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME10SNR20 = \"DevOpsTest10SNR20\"\n",
    "recreateTable(TABLE_NAME10SNR20, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 120  --seed 1234 \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME10SNR20\" --region \"$REGION\" \\\n",
    "  --include-region \"eu-central-1\" --include-ms \"athena\" \\\n",
    "  --sin-signal-cpu 20 --sin-frq-cpu m \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"WITH offsetted AS (\n",
    "         SELECT time, \n",
    "                measure_value::double value,\n",
    "                lag(time, 60) OVER (order by time rows 60 preceding) as lagtime,\n",
    "                lag(measure_value::double, 60) OVER (order by time rows 60 preceding) as lagvalue\n",
    "           FROM {}.{}\n",
    "          WHERE 1=1\n",
    "            AND measure_name = 'cpu_user')\n",
    "         SELECT count(1) as cnt, round(sum(value), 2) as sum, round(sum(value - lagvalue),2) as dif\n",
    "           FROM offsetted\n",
    "          WHERE lagtime is not null\"\"\".format(DB_NAME, TABLE_NAME10SNR20)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 60:\n",
    "    print('\\x1B[91m' + 'TEST 10-1: FAILED: We expect 60 records with value and lagvalue. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 10-1: SUCCESS: We expect 60 records with value and lagvalue.')\n",
    "\n",
    "if (result1['sum'][0] <= 2990):\n",
    "    print('\\x1B[91m' + 'TEST 10-2: FAILED: We expect a sum of > 2990 - noise should averaged out.. Actual {}'.format(result1['sum'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 10-2: SUCCESS: We expect a sum of > 2990 - noise should averaged out.')\n",
    "\n",
    "if (abs(result1['dif'][0]) >= 10 ):\n",
    "    print('\\x1B[91m' + 'TEST 10-3: FAILED:  We expect a difference of < 10. Actual {}'.format(result1['dif'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 10-3: SUCCESS: We expect a difference of < 10')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 10: DONE') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 11: Sinus Signal Values SNR1\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 11 SNR 1: Run ingestor simulating 'eu-central-1' and 'athena' service with sinus signal on CPU with SNR=1\n",
    "## Signal equally strong than noise => noise = [-50 ... 50] for signal = [0 ... 100]\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME11SNR1 = \"DevOpsTest11SNR1\"\n",
    "recreateTable(TABLE_NAME11SNR1, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 120  --seed 1234 \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME11SNR1\" --region \"$REGION\" \\\n",
    "  --include-region \"eu-central-1\" --include-ms \"athena\" \\\n",
    "  --sin-signal-cpu 1 --sin-frq-cpu m \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"WITH offsetted AS (\n",
    "         SELECT time, \n",
    "                measure_value::double value,\n",
    "                lag(time, 60) OVER (order by time rows 60 preceding) as lagtime,\n",
    "                lag(measure_value::double, 60) OVER (order by time rows 60 preceding) as lagvalue\n",
    "           FROM {}.{}\n",
    "          WHERE 1=1\n",
    "            AND measure_name = 'cpu_user')\n",
    "         SELECT count(1) as cnt, round(sum(value), 2) as sum, round(sum(value - lagvalue),2) as dif\n",
    "           FROM offsetted\n",
    "          WHERE lagtime is not null\"\"\".format(DB_NAME, TABLE_NAME11SNR1)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 60:\n",
    "    print('\\x1B[91m' + 'TEST 11-1: FAILED: We expect 60 records with value and lagvalue. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 11-1: SUCCESS: We expect 60 records with value and lagvalue.')\n",
    "\n",
    "if result1['sum'][0] < 2800:\n",
    "    print('\\x1B[91m' + 'TEST 11-2: FAILED: We expect a sum of 2500 or more. Actual {}'.format(result1['sum'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 11-2: SUCCESS: We expect a sum of 2500 or more')\n",
    " \n",
    "if abs(result1['dif'][0]) >= 200:\n",
    "    print('\\x1B[91m' + 'TEST 11-3: FAILED: We expect a difference of -200 to 200. Actual {}'.format(result1['dif'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 11-3: SUCCESS: We expect a difference of -200 to 200')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 11: DONE') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 12: Saw Signal Values SNR100\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 12: Run ingestor simulating 'eu-central-1' and 'athena' service with saw signal on CPU (no noise)\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME12SNR100 = \"DevOpsTest12SNR100\"\n",
    "recreateTable(TABLE_NAME12SNR100, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 120  --seed 1234 \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME12SNR100\" --region \"$REGION\" \\\n",
    "  --include-region \"eu-central-1\" --include-ms \"athena\" \\\n",
    "  --saw-signal-cpu 100 --saw-frq-cpu m \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"WITH offsetted AS (\n",
    "         SELECT time, \n",
    "                measure_value::double value,\n",
    "                lag(time, 60) OVER (order by time rows 60 preceding) as lagtime,\n",
    "                lag(measure_value::double, 60) OVER (order by time rows 60 preceding) as lagvalue\n",
    "           FROM {}.{}\n",
    "          WHERE 1=1\n",
    "            AND measure_name = 'cpu_user')\n",
    "         SELECT count(1) as cnt, round(sum(value), 2) as sum, round(sum(value - lagvalue),2) as dif\n",
    "           FROM offsetted\n",
    "          WHERE lagtime is not null\"\"\".format(DB_NAME, TABLE_NAME12SNR100)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 60:\n",
    "    print('\\x1B[91m' + 'TEST 12-1: FAILED: We expect 60 records with value and lagvalue. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 12-1: SUCCESS: We expect 60 records with value and lagvalue.')\n",
    "\n",
    "if result1['sum'][0] < 2950:\n",
    "    print('\\x1B[91m' + 'TEST 12-2: FAILED: We expect a sum of 2950 or 3000. Actual {}'.format(result1['sum'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 12-2: SUCCESS: We expect a sum of 2950 or 3000')\n",
    "\n",
    "if result1['dif'][0] != 0:\n",
    "    print('\\x1B[91m' + 'TEST 12-3: FAILED: We expect a difference of 0. Actual {}'.format(result1['dif'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 12-3: SUCCESS: We expect a difference of 0')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 12: DONE') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 13: Saw Signal Values SNR10\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## TEST 13: Run ingestor simulating 'eu-central-1' and 'athena' service with saw signal on CPU (no noise)\n",
    "###################################################################################################\n",
    "\n",
    "TABLE_NAME13SNR10 = \"DevOpsTest13SNR10\"\n",
    "recreateTable(TABLE_NAME13SNR10, DB_NAME)\n",
    "\n",
    "%run timestream_sample_continuous_data_ingestor_application.py --autostop 120  --seed 1234 \\\n",
    "  --database-name \"$DB_NAME\" --table-name \"$TABLE_NAME13SNR10\" --region \"$REGION\" \\\n",
    "  --include-region \"eu-central-1\" --include-ms \"athena\" \\\n",
    "  --saw-signal-cpu 10 --saw-frq-cpu m \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"WITH offsetted AS (\n",
    "         SELECT time, \n",
    "                measure_value::double value,\n",
    "                lag(time, 60) OVER (order by time rows 60 preceding) as lagtime,\n",
    "                lag(measure_value::double, 60) OVER (order by time rows 60 preceding) as lagvalue\n",
    "           FROM {}.{}\n",
    "          WHERE 1=1\n",
    "            AND measure_name = 'cpu_user')\n",
    "         SELECT count(1) as cnt, round(sum(value), 2) as sum, round(sum(value - lagvalue),2) as dif\n",
    "           FROM offsetted\n",
    "          WHERE lagtime is not null\"\"\".format(DB_NAME, TABLE_NAME13SNR10)\n",
    "result1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "if result1['cnt'][0] != 60:\n",
    "    print('\\x1B[91m' + 'TEST 13-1: FAILED: We expect 60 records with value and lagvalue. Actual {}'.format(result1['cnt'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 13-1: SUCCESS: We expect 60 records with value and lagvalue.')\n",
    "\n",
    "if result1['sum'][0] < 2900:\n",
    "    print('\\x1B[91m' + 'TEST 13-2: FAILED: We expect a sum of 2950 or 3000 +/- noise. Actual {}'.format(result1['sum'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 13-2: SUCCESS: We expect a sum of 2950 or 3000')\n",
    "\n",
    "if result1['dif'][0] > 10:\n",
    "    print('\\x1B[91m' + 'TEST 13-3: FAILED: We expect a difference of less than 10. Actual {}'.format(result1['dif'][0]))\n",
    "else:\n",
    "    print('\\x1b[92m' + 'TEST 13-3: SUCCESS: We expect a difference of less than 10')\n",
    "\n",
    "print('\\x1b[0m' + 'TEST 13: DONE') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Signals\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT time, measure_value::double as cpu_user\n",
    "             FROM {}.{}\n",
    "            WHERE 1=1\n",
    "              AND measure_name = 'cpu_user'\n",
    "            ORDER BY time \n",
    "            LIMIT 250\"\"\".format(DB_NAME, TABLE_NAME9SNR100)\n",
    "resultSIN100 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "query = \"\"\"SELECT time, measure_value::double as cpu_user\n",
    "             FROM {}.{}\n",
    "            WHERE 1=1\n",
    "              AND measure_name = 'cpu_user'\n",
    "            ORDER BY time \n",
    "            LIMIT 250\"\"\".format(DB_NAME, TABLE_NAME10SNR20)\n",
    "resultSIN20 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "query = \"\"\"SELECT time, measure_value::double as cpu_user\n",
    "             FROM {}.{}\n",
    "            WHERE 1=1\n",
    "              AND measure_name = 'cpu_user'\n",
    "            ORDER BY time \n",
    "            LIMIT 250\"\"\".format(DB_NAME, TABLE_NAME11SNR1)\n",
    "resultSIN1 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "query = \"\"\"SELECT time, measure_value::double as cpu_user\n",
    "             FROM {}.{}\n",
    "            WHERE 1=1\n",
    "              AND measure_name = 'cpu_user'\n",
    "            ORDER BY time \n",
    "            LIMIT 250\"\"\".format(DB_NAME, TABLE_NAME12SNR100)\n",
    "resultSAW100 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "query = \"\"\"SELECT time, measure_value::double as cpu_user\n",
    "             FROM {}.{}\n",
    "            WHERE 1=1\n",
    "              AND measure_name = 'cpu_user'\n",
    "            ORDER BY time \n",
    "            LIMIT 250\"\"\".format(DB_NAME, TABLE_NAME13SNR10)\n",
    "resultSAW10 = timestream.executeQueryAndReturnAsDataframe(read_client, query, True)\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "fig, ax = plt.subplots(5)\n",
    "\n",
    "ax[0].title.set_text('CPU User - Sinus SNR 100 - as Recorded')\n",
    "ax[0].plot(resultSIN100['time'], resultSIN100['cpu_user'], color='darkorange', \\\n",
    "           marker='+', markersize=12, mew=2, linewidth=0.5, alpha=0.5)\n",
    "ax[0].grid(which ='both', axis ='both', linestyle ='--')\n",
    "\n",
    "ax[1].title.set_text('CPU User - Sinus SNR 20 - as Recorded')\n",
    "ax[1].plot(resultSIN20['time'], resultSIN20['cpu_user'], color='darkorange', \\\n",
    "          marker='+', markersize=12, mew=2, linewidth=0.5, alpha=0.5)\n",
    "ax[1].grid(which ='both', axis ='both', linestyle ='--')\n",
    "\n",
    "ax[2].title.set_text('CPU User - Sinus SNR 1 - as Recorded')\n",
    "ax[2].plot(resultSIN1['time'], resultSIN1['cpu_user'], color='darkorange', \\\n",
    "          marker='+', markersize=12, mew=2, linewidth=0.5, alpha=0.5)\n",
    "ax[2].grid(which ='both', axis ='both', linestyle ='--')\n",
    "\n",
    "\n",
    "ax[3].title.set_text('CPU User - Saw SNR 100 - as Recorded')\n",
    "ax[3].plot(resultSAW100['time'], resultSAW100['cpu_user'], color='darkgreen', \\\n",
    "           marker='+', markersize=12, mew=2, linewidth=0.5, alpha=0.5)\n",
    "ax[3].grid(which ='both', axis ='both', linestyle ='--')\n",
    "\n",
    "ax[4].title.set_text('CPU User - Saw SNR 10 - as Recorded')\n",
    "ax[4].plot(resultSAW10['time'], resultSAW10['cpu_user'], color='darkgreen', \\\n",
    "           marker='+', markersize=12, mew=2, linewidth=0.5, alpha=0.5)\n",
    "ax[4].grid(which ='both', axis ='both', linestyle ='--')\n",
    "ax[4].set_xticklabels('', visilbe=False)\n",
    "\n",
    "fig.autofmt_xdate(rotation=60)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "plt.savefig('sinsawsnr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup: Drop Tables and Database\n",
    "(Back to [top](#Contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP Database and Tables (Stop if there is a table we dont know.)\n",
    "\n",
    "CLEANUP = \"\"\n",
    "if \"DELETE\" == CLEANUP:\n",
    "    try:\n",
    "        result = write_client.list_tables(DatabaseName=DB_NAME, MaxResults=20)\n",
    "        to_be_dropped = list()\n",
    "        for table in result['Tables']:\n",
    "            tableName = table['TableName']\n",
    "            if (tableName.startswith(\"DevOpsTest\")):\n",
    "                print('Going to drop table <' + tableName + '>' )\n",
    "                to_be_dropped.append(tableName)\n",
    "            else:\n",
    "                raise AssertionError(\"Found table <\" + tableName +\"> which does not start with <DevOpsTest> - stopping process.\")\n",
    "\n",
    "        for tableToDrop in to_be_dropped:\n",
    "            write_client.delete_table(DatabaseName=DB_NAME, TableName=tableToDrop)\n",
    "            print(\"Table <{}> deleted.\".format(tableToDrop))\n",
    "\n",
    "        write_client.delete_database(DatabaseName=DB_NAME)\n",
    "        print(\"Database <{}> deleted.\".format(DB_NAME))\n",
    "    except AssertionError as e:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        if \"ResourceNotFoundException\" == e.response['Error']['Code']:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
